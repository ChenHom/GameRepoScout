#!/usr/bin/env python3
"""
github_game_finder.py
å¾ GitHub æœå°‹ç¬¦åˆæ¢ä»¶çš„éŠæˆ²å°ˆæ¡ˆä¸¦è¼¸å‡º CSV
"""

import csv
import os
import time
from datetime import datetime
from typing import List, Dict

import requests
from dotenv import load_dotenv
from urllib.parse import quote_plus

# -------------- åŸºæœ¬åƒæ•¸ ------------------
QUERY_KEYWORDS = "game unity 2d"            # é—œéµå­—ï¼ˆç©ºç™½åˆ†éš” = ANDï¼‰
TOPICS         = ["unity", "2d"]            # topics: unity AND 2d
LANGUAGE       = "C#"                       # èªè¨€
MIN_STARS      = 200                        # æ˜Ÿæ•¸ä¸‹é™
PUSHED_AFTER   = "2024-12-01"               # æœ€å¾Œæ›´æ–°ä¸å¾—æ—©æ–¼
LICENSES       = ["mit", "apache-2.0"]      # æˆæ¬Šç™½åå–®ï¼ˆå°å¯«ï¼‰
PER_PAGE       = 100                        # GitHub ä¸Šé™
MAX_PAGES      = 10                         # æœ€å¤šæŠ“ 1,000 ç­†
OUTPUT_FILE    = "github_games.csv"
# ------------------------------------------

API_URL = "https://api.github.com/search/repositories"
load_dotenv()
TOKEN = os.getenv("GITHUB_TOKEN")
HEADERS = {"Authorization": f"token {TOKEN}"} if TOKEN else {}

def build_query() -> str:
    q = []
    if QUERY_KEYWORDS:
        q.append(quote_plus(QUERY_KEYWORDS))
    for t in TOPICS:
        q.append(f"topic:{t}")
    if LANGUAGE:
        q.append(f"language:{LANGUAGE}")
    if MIN_STARS:
        q.append(f"stars:>={MIN_STARS}")
    if PUSHED_AFTER:
        q.append(f"pushed:>={PUSHED_AFTER}")
    return "+".join(q)

def fetch_page(page: int) -> Dict:
    params = {
        "q": build_query(),
        "sort": "stars",
        "order": "desc",
        "per_page": PER_PAGE,
        "page": page,
    }
    resp = requests.get(API_URL, headers=HEADERS, params=params, timeout=30)
    resp.raise_for_status()
    return resp.json()

def filter_by_license(items) -> List[Dict]:
    if not LICENSES:
        return items
    return [
        it for it in items
        if it.get("license") and it["license"]["spdx_id"].lower() in LICENSES
    ]

def to_row(it) -> List:
    return [
        it["full_name"],
        it["html_url"],
        it["stargazers_count"],
        it["pushed_at"][:10],
        it["license"]["spdx_id"] if it.get("license") else "N/A",
    ]

def main():
    print("ğŸ”  æ­£åœ¨æœå°‹ GitHub éŠæˆ²å°ˆæ¡ˆâ€¦")
    rows = []
    for page in range(1, MAX_PAGES + 1):
        data = fetch_page(page)
        items = filter_by_license(data.get("items", []))
        rows.extend([to_row(it) for it in items])
        print(f"  - å–å¾—ç¬¬ {page} é ï¼Œå…± {len(items)} ç­†ï¼ˆç´¯è¨ˆ {len(rows)}ï¼‰")
        time.sleep(1)  # é¿å…éåº¦è§¸ç™¼é€Ÿç‡é™åˆ¶
        if len(data.get("items", [])) < PER_PAGE:
            break

    with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["repo_name", "html_url", "stars", "last_pushed", "license"])
        writer.writerows(rows)

    print(f"âœ… å®Œæˆï¼çµæœå·²è¼¸å‡ºè‡³ {OUTPUT_FILE}ï¼ˆ{len(rows)} ç­†ï¼‰")

if __name__ == "__main__":
    if not TOKEN:
        print("âŒ è«‹å…ˆåœ¨ .env è¨­å®š GITHUB_TOKEN")
    else:
        main()
